# -*- coding: utf-8 -*-
"""
Grid Search cho Histogram Features
T√¨m tham s·ªë t·ªët nh·∫•t cho Histogram b·∫±ng c√°ch ƒë√°nh gi√° tr√™n t·∫≠p validation (20% t·ª´ train)
"""

import sys
import io
import numpy as np
import time
import pickle
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from itertools import product

# C·∫•u h√¨nh encoding UTF-8 cho Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from histogram_feature import extract_histogram_from_dataset


def grid_search_histogram():
    """
    Grid search ƒë·ªÉ t√¨m tham s·ªë t·ªët nh·∫•t cho Histogram
    """
    print("=" * 80)
    print("GRID SEARCH - HISTOGRAM FEATURES")
    print("=" * 80)
    
    # ƒê·ªãnh nghƒ©a grid tham s·ªë cho Feature Extraction
    param_grid = {
        'target_size': [(64, 64), (128, 128), (256, 256)],
        'color_space': ['BGR', 'RGB', 'HSV', 'Lab'],
        'bins': [
            (8, 8, 8),
            (16, 16, 16),
            (18, 8, 8),    # Khuy·∫øn ngh·ªã cho HSV
            (32, 16, 16),
        ],
    }
    
    # ƒê·ªãnh nghƒ©a grid tham s·ªë cho SVM
    svm_param_grid = {
        'kernel': ['rbf', 'linear'],
        'C': [0.1, 1, 10],
        'gamma': ['scale']  # ch·ªâ d√πng v·ªõi kernel='rbf'
    }
    
    print("\nüìã Grid tham s·ªë Feature Extraction:")
    for param, values in param_grid.items():
        print(f"   - {param}: {values}")
    
    print(f"\nüìã Grid tham s·ªë SVM:")
    for param, values in svm_param_grid.items():
        print(f"   - {param}: {values}")
    
    # T√≠nh t·ªïng s·ªë combinations
    feature_combinations = np.prod([len(v) for v in param_grid.values()])
    svm_combinations = len(svm_param_grid['kernel']) * len(svm_param_grid['C']) * len(svm_param_grid['gamma'])
    total_combinations = feature_combinations * svm_combinations
    
    print(f"\nüìä Feature combinations: {feature_combinations}")
    print(f"üìä SVM combinations: {svm_combinations}")
    print(f"üìä T·ªïng s·ªë combinations: {total_combinations}")
    
    # T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    results_dir = 'grid_search_results'
    os.makedirs(results_dir, exist_ok=True)
    
    # L∆∞u k·∫øt qu·∫£
    results = []
    best_accuracy = 0
    best_params = None
    
    # ƒê·∫øm combination
    current_combination = 0
    
    print("\n" + "=" * 80)
    print("B·∫ÆT ƒê·∫¶U GRID SEARCH")
    print("=" * 80)
    
    # Grid search - Nested loop cho Feature params v√† SVM params
    for target_size, color_space, bins in product(
        param_grid['target_size'],
        param_grid['color_space'],
        param_grid['bins']
    ):
        print(f"\n{'='*80}")
        print(f"Feature params: target_size={target_size}, color_space={color_space}, bins={bins}")
        print(f"{'='*80}")
        
        try:
            # 1. Tr√≠ch xu·∫•t features t·ª´ train set (ch·ªâ 1 l·∫ßn cho m·ªói feature params)
            print("   ‚Üí Tr√≠ch xu·∫•t features t·ª´ train set...")
            feature_start_time = time.time()
            
            X_train_full, y_train_full, class_names = extract_histogram_from_dataset(
                'vn-signs/train',
                target_size=target_size,
                color_space=color_space,
                bins=bins,
                normalize=True,
                use_cache=False  # Kh√¥ng d√πng cache v√¨ m·ªói l·∫ßn kh√°c tham s·ªë
            )
            
            if len(X_train_full) == 0:
                print("   ‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c features, skip...")
                continue
            
            # Convert to numpy array
            X_train_full = np.array(X_train_full)
            
            # Encode labels
            label_encoder = LabelEncoder()
            y_train_full = label_encoder.fit_transform(y_train_full)
            
            # 2. Chia train/validation (80/20)
            X_train, X_val, y_train, y_val = train_test_split(
                X_train_full, y_train_full,
                test_size=0.2,
                random_state=42,
                stratify=y_train_full
            )
            
            print(f"   ‚Üí Train: {X_train.shape[0]} samples, Validation: {X_val.shape[0]} samples")
            print(f"   ‚Üí Feature extraction time: {time.time() - feature_start_time:.2f}s")
            
            # 3. Chu·∫©n h√≥a (ch·ªâ 1 l·∫ßn)
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_val_scaled = scaler.transform(X_val)
            
            # 4. Th·ª≠ t·∫•t c·∫£ c√°c SVM params
            for kernel, C, gamma in product(
                svm_param_grid['kernel'],
                svm_param_grid['C'],
                svm_param_grid['gamma']
            ):
                current_combination += 1
                
                # Gamma ch·ªâ √°p d·ª•ng cho RBF kernel
                if kernel == 'linear' and gamma not in ['scale', 'auto']:
                    continue
                
                print(f"\n   [{current_combination}/{total_combinations}] SVM: kernel={kernel}, C={C}, gamma={gamma}")
                
                try:
                    svm_start_time = time.time()
                    
                    # Train SVM
                    if kernel == 'linear':
                        svm = SVC(kernel=kernel, C=C, random_state=42)
                    else:  # rbf
                        svm = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)
                    
                    svm.fit(X_train_scaled, y_train)
                    
                    # ƒê√°nh gi√° tr√™n validation
                    y_val_pred = svm.predict(X_val_scaled)
                    val_accuracy = accuracy_score(y_val, y_val_pred)
                    
                    # ƒê√°nh gi√° tr√™n train
                    y_train_pred = svm.predict(X_train_scaled)
                    train_accuracy = accuracy_score(y_train, y_train_pred)
                    
                    svm_time = time.time() - svm_start_time
                    
                    print(f"      ‚úì Train Accuracy: {train_accuracy*100:.2f}%")
                    print(f"      ‚úì Val Accuracy:   {val_accuracy*100:.2f}%")
                    print(f"      ‚úì SVM Time: {svm_time:.2f}s")
                    
                    # L∆∞u k·∫øt qu·∫£
                    result = {
                        'target_size': target_size,
                        'color_space': color_space,
                        'bins': bins,
                        'kernel': kernel,
                        'C': C,
                        'gamma': gamma if kernel == 'rbf' else None,
                        'train_accuracy': train_accuracy,
                        'val_accuracy': val_accuracy,
                        'time': svm_time,
                        'feature_dim': X_train.shape[1]
                    }
                    results.append(result)
                    
                    # C·∫≠p nh·∫≠t best
                    if val_accuracy > best_accuracy:
                        best_accuracy = val_accuracy
                        best_params = result.copy()
                        print(f"      üèÜ NEW BEST! Val Accuracy: {best_accuracy*100:.2f}%")
                
                except Exception as e:
                    print(f"      ‚ùå L·ªói SVM: {e}")
                    continue
            
        except Exception as e:
            print(f"   ‚ùå L·ªói feature extraction: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    print("\n" + "=" * 80)
    print("K·∫æT QU·∫¢ GRID SEARCH")
    print("=" * 80)
    
    if len(results) > 0:
        # S·∫Øp x·∫øp theo validation accuracy
        results_sorted = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)
        
        print(f"\nüèÜ TOP 10 BEST CONFIGURATIONS:")
        print("-" * 80)
        for i, result in enumerate(results_sorted[:10], 1):
            print(f"\n{i}. Val Accuracy: {result['val_accuracy']*100:.2f}% | "
                  f"Train Accuracy: {result['train_accuracy']*100:.2f}%")
            print(f"   Feature: target_size={result['target_size']}, color_space={result['color_space']}, bins={result['bins']}")
            print(f"   SVM: kernel={result['kernel']}, C={result['C']}, gamma={result['gamma']}")
            print(f"   Feature dim: {result['feature_dim']}, Time: {result['time']:.2f}s")
        
        # L∆∞u k·∫øt qu·∫£ v√†o file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = os.path.join(results_dir, f'histogram_grid_search_{timestamp}.pkl')
        
        with open(result_file, 'wb') as f:
            pickle.dump({
                'results': results,
                'best_params': best_params,
                'param_grid': param_grid,
                'svm_param_grid': svm_param_grid
            }, f)
        
        print(f"\nüíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {result_file}")
        
        # L∆∞u k·∫øt qu·∫£ d·∫°ng text
        txt_file = os.path.join(results_dir, f'histogram_grid_search_{timestamp}.txt')
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("GRID SEARCH RESULTS - HISTOGRAM FEATURES\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total combinations tested: {len(results)}\n\n")
            
            f.write("BEST CONFIGURATION:\n")
            f.write("-" * 80 + "\n")
            f.write(f"Validation Accuracy: {best_params['val_accuracy']*100:.2f}%\n")
            f.write(f"Train Accuracy: {best_params['train_accuracy']*100:.2f}%\n")
            f.write(f"\nFeature Extraction Parameters:\n")
            f.write(f"  target_size: {best_params['target_size']}\n")
            f.write(f"  color_space: {best_params['color_space']}\n")
            f.write(f"  bins: {best_params['bins']}\n")
            f.write(f"\nSVM Parameters:\n")
            f.write(f"  kernel: {best_params['kernel']}\n")
            f.write(f"  C: {best_params['C']}\n")
            f.write(f"  gamma: {best_params['gamma']}\n")
            f.write(f"\nOther Info:\n")
            f.write(f"  Feature dimension: {best_params['feature_dim']}\n")
            f.write(f"  Time: {best_params['time']:.2f}s\n\n")
            
            f.write("\nALL RESULTS (sorted by validation accuracy):\n")
            f.write("-" * 80 + "\n")
            for i, result in enumerate(results_sorted, 1):
                f.write(f"\n{i}. Val Acc: {result['val_accuracy']*100:.2f}% | "
                       f"Train Acc: {result['train_accuracy']*100:.2f}%\n")
                f.write(f"   {result}\n")
        
        print(f"üíæ ƒê√£ l∆∞u b√°o c√°o text: {txt_file}")
        
        print("\n" + "=" * 80)
        print("‚úÖ HO√ÄN TH√ÄNH GRID SEARCH!")
        print("=" * 80)
    else:
        print("\n‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o!")


if __name__ == "__main__":
    grid_search_histogram()

