# -*- coding: utf-8 -*-
"""
Ph√¢n t√≠ch k·∫øt qu·∫£ Grid Search cho CCV Features
Hu·∫•n luy·ªán v√† ƒë√°nh gi√° t·ª´ng b·ªô tham s·ªë SVM t·ªët nh·∫•t tr√™n t·∫≠p test
"""

import sys
import io
import pickle
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib

# C·∫•u h√¨nh encoding UTF-8 cho Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from ccv_feature import extract_ccv_from_dataset


def analyze_grid_search_results(result_file):
    """
    ƒê·ªçc v√† ph√¢n t√≠ch k·∫øt qu·∫£ grid search
    
    Args:
        result_file: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file .pkl ch·ª©a k·∫øt qu·∫£
    
    Returns:
        svm_best_results_sorted: Danh s√°ch c√°c b·ªô tham s·ªë SVM t·ªët nh·∫•t
    """
    print("=" * 100)
    print("PH√ÇN T√çCH K·∫æT QU·∫¢ GRID SEARCH - CCV FEATURES")
    print("=" * 100)
    
    # ƒê·ªçc file k·∫øt qu·∫£
    try:
        with open(result_file, 'rb') as f:
            data = pickle.load(f)
        
        results = data['results']
        best_params = data['best_params']
        param_grid = data.get('param_grid', {})
        svm_param_grid = data.get('svm_param_grid', {})
        
        print(f"\nüìÅ File: {result_file}")
        print(f"üìä T·ªïng s·ªë k·∫øt qu·∫£: {len(results)}")
        
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file: {e}")
        return None
    
    # ========================================================================
    # PH√ÇN T√çCH T·ªîNG QUAN
    # ========================================================================
    print("\n" + "=" * 100)
    print("PH√ÇN T√çCH T·ªîNG QUAN")
    print("=" * 100)
    
    # Nh√≥m k·∫øt qu·∫£ theo tham s·ªë SVM
    svm_to_ccv = defaultdict(list)
    
    for result in results:
        kernel = result['kernel']
        C = result['C']
        gamma = result.get('gamma', None)  # CCV c√≥ th·ªÉ c√≥ gamma=None cho linear kernel
        svm_key = (kernel, C, gamma)
        
        ccv_params = {
            'target_size': result['target_size'],
            'n_bins': result['n_bins'],
            'threshold': result['threshold'],
            'color_space': result['color_space'],
            'val_accuracy': result['val_accuracy'],
            'train_accuracy': result['train_accuracy'],
            'feature_dim': result['feature_dim'],
            'time': result['time']
        }
        
        svm_to_ccv[svm_key].append(ccv_params)
    
    # T·∫≠p h·ª£p c√°c tham s·ªë SVM duy nh·∫•t
    svm_params_set = set()
    for result in results:
        kernel = result['kernel']
        C = result['C']
        gamma = result.get('gamma', None)
        svm_params_set.add((kernel, C, gamma))
    
    svm_params_list = sorted(list(svm_params_set))
    
    # T√¨m best result cho m·ªói t·∫≠p tham s·ªë SVM
    print("\nüèÜ K·∫æT QU·∫¢ T·ªêT NH·∫§T CHO M·ªñI T·∫¨P THAM S·ªê SVM:")
    print("-" * 100)
    
    svm_best_results = []
    for svm_key in svm_params_list:
        ccv_list = svm_to_ccv[svm_key]
        best_ccv = max(ccv_list, key=lambda x: x['val_accuracy'])
        
        svm_best_results.append({
            'kernel': svm_key[0],
            'C': svm_key[1],
            'gamma': svm_key[2],
            'best_val_acc': best_ccv['val_accuracy'],
            'best_ccv': best_ccv
        })
    
    # S·∫Øp x·∫øp theo val_accuracy
    svm_best_results_sorted = sorted(svm_best_results, key=lambda x: x['best_val_acc'], reverse=True)
    
    for i, result in enumerate(svm_best_results_sorted, 1):
        gamma_str = str(result['gamma']) if result['gamma'] is not None else 'None'
        print(f"\n{i:2d}. SVM: kernel={result['kernel']:8s} | C={result['C']:6.1f} | gamma={gamma_str}")
        print(f"    Best Val Acc: {result['best_val_acc']*100:.2f}%")
        print(f"    Best CCV: target_size={result['best_ccv']['target_size']}, "
              f"n_bins={result['best_ccv']['n_bins']}, "
              f"threshold={result['best_ccv']['threshold']}, "
              f"color_space={result['best_ccv']['color_space']}")
    
    return svm_best_results_sorted


def train_and_evaluate_svm_config(config, config_idx, total_configs, results_base_dir='ccv_results'):
    """
    Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m·ªôt c·∫•u h√¨nh SVM tr√™n t·∫≠p test
    
    Args:
        config: Dictionary ch·ª©a th√¥ng tin c·∫•u h√¨nh SVM v√† CCV
        config_idx: Ch·ªâ s·ªë c·∫•u h√¨nh (1-based)
        total_configs: T·ªïng s·ªë c·∫•u h√¨nh
        results_base_dir: Th∆∞ m·ª•c g·ªëc l∆∞u k·∫øt qu·∫£
    """
    print("\n" + "=" * 100)
    print(f"[{config_idx}/{total_configs}] HU·∫§N LUY·ªÜN V√Ä ƒê√ÅNH GI√Å")
    print("=" * 100)
    
    # L·∫•y tham s·ªë
    kernel = config['kernel']
    C = config['C']
    gamma = config['gamma']
    ccv_params = config['best_ccv']
    
    target_size = ccv_params['target_size']
    n_bins = ccv_params['n_bins']
    threshold = ccv_params['threshold']
    color_space = ccv_params['color_space']
    
    print(f"\nüìã SVM Parameters:")
    print(f"   kernel: {kernel}")
    print(f"   C:      {C}")
    print(f"   gamma:  {gamma}")
    
    print(f"\nüìã CCV Parameters:")
    print(f"   target_size:  {target_size}")
    print(f"   n_bins:       {n_bins}")
    print(f"   threshold:    {threshold}")
    print(f"   color_space:  {color_space}")
    
    # T·∫°o t√™n th∆∞ m·ª•c
    if kernel == 'linear':
        folder_name = f"svm_kernel-{kernel}_C-{C}"
    else:
        gamma_str = str(gamma) if gamma is not None else 'None'
        folder_name = f"svm_kernel-{kernel}_C-{C}_gamma-{gamma_str}"
    
    result_dir = os.path.join(results_base_dir, folder_name)
    os.makedirs(result_dir, exist_ok=True)
    
    print(f"\nüìÅ Th∆∞ m·ª•c k·∫øt qu·∫£: {result_dir}")
    
    try:
        # ====================================================================
        # 1. TR√çCH XU·∫§T FEATURES
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 1: TR√çCH XU·∫§T FEATURES")
        print("-" * 100)
        
        # Train set
        print("\n‚Üí Tr√≠ch xu·∫•t features t·ª´ train set...")
        X_train, y_train, class_names = extract_ccv_from_dataset(
            'vn-signs/train',
            target_size=target_size,
            n_bins=n_bins,
            threshold=threshold,
            color_space=color_space,
            use_cache=False
        )
        
        X_train = np.array(X_train)
        print(f"   ‚úì Train: {X_train.shape[0]} samples, {X_train.shape[1]} features")
        
        # Test set
        print("\n‚Üí Tr√≠ch xu·∫•t features t·ª´ test set...")
        X_test, y_test, _ = extract_ccv_from_dataset(
            'vn-signs/test',
            target_size=target_size,
            n_bins=n_bins,
            threshold=threshold,
            color_space=color_space,
            use_cache=False
        )
        
        X_test = np.array(X_test)
        print(f"   ‚úì Test:  {X_test.shape[0]} samples, {X_test.shape[1]} features")
        
        # ====================================================================
        # 2. ENCODE LABELS
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 2: ENCODE LABELS")
        print("-" * 100)
        
        label_encoder = LabelEncoder()
        y_train_encoded = label_encoder.fit_transform(y_train)
        y_test_encoded = label_encoder.transform(y_test)
        
        print(f"   ‚úì Classes: {list(label_encoder.classes_)}")
        print(f"   ‚úì Number of classes: {len(label_encoder.classes_)}")
        
        # L∆∞u label encoder
        le_path = os.path.join(result_dir, 'label_encoder.pkl')
        joblib.dump(label_encoder, le_path)
        print(f"   ‚úì ƒê√£ l∆∞u label encoder: {le_path}")
        
        # ====================================================================
        # 3. CHU·∫®N H√ìA
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 3: CHU·∫®N H√ìA")
        print("-" * 100)
        
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        print(f"   ‚úì ƒê√£ chu·∫©n h√≥a train v√† test sets")
        
        # L∆∞u scaler
        scaler_path = os.path.join(result_dir, 'scaler.pkl')
        joblib.dump(scaler, scaler_path)
        print(f"   ‚úì ƒê√£ l∆∞u scaler: {scaler_path}")
        
        # ====================================================================
        # 4. HU·∫§N LUY·ªÜN SVM
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 4: HU·∫§N LUY·ªÜN SVM")
        print("-" * 100)
        
        import time
        start_time = time.time()
        
        if kernel == 'linear':
            svm = SVC(kernel=kernel, C=C, random_state=42)
        else:
            if gamma is not None:
                svm = SVC(kernel=kernel, C=C, gamma=gamma, random_state=42)
            else:
                svm = SVC(kernel=kernel, C=C, random_state=42)
        
        svm.fit(X_train_scaled, y_train_encoded)
        
        training_time = time.time() - start_time
        print(f"   ‚úì Th·ªùi gian hu·∫•n luy·ªán: {training_time:.2f}s")
        
        # L∆∞u model
        model_path = os.path.join(result_dir, 'svm_model.pkl')
        joblib.dump(svm, model_path)
        print(f"   ‚úì ƒê√£ l∆∞u model: {model_path}")
        
        # ====================================================================
        # 5. D·ª∞ ƒêO√ÅN V√Ä ƒê√ÅNH GI√Å
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 5: D·ª∞ ƒêO√ÅN V√Ä ƒê√ÅNH GI√Å")
        print("-" * 100)
        
        # D·ª± ƒëo√°n tr√™n train
        y_train_pred = svm.predict(X_train_scaled)
        train_accuracy = accuracy_score(y_train_encoded, y_train_pred)
        
        # D·ª± ƒëo√°n tr√™n test
        y_test_pred = svm.predict(X_test_scaled)
        test_accuracy = accuracy_score(y_test_encoded, y_test_pred)
        
        print(f"\n   üìä Train Accuracy: {train_accuracy*100:.2f}%")
        print(f"   üìä Test Accuracy:  {test_accuracy*100:.2f}%")
        
        # ====================================================================
        # 6. L∆ØU CLASSIFICATION REPORT
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 6: L∆ØU CLASSIFICATION REPORT")
        print("-" * 100)
        
        report = classification_report(
            y_test_encoded, 
            y_test_pred, 
            target_names=label_encoder.classes_,
            digits=4
        )
        
        print("\n" + report)
        
        # L∆∞u v√†o file
        report_path = os.path.join(result_dir, 'classification_report.txt')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("CLASSIFICATION REPORT\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"SVM Parameters:\n")
            f.write(f"  kernel: {kernel}\n")
            f.write(f"  C:      {C}\n")
            f.write(f"  gamma:  {gamma}\n\n")
            f.write(f"CCV Parameters:\n")
            f.write(f"  target_size:  {target_size}\n")
            f.write(f"  n_bins:       {n_bins}\n")
            f.write(f"  threshold:    {threshold}\n")
            f.write(f"  color_space:  {color_space}\n\n")
            f.write(f"Results:\n")
            f.write(f"  Train Accuracy: {train_accuracy*100:.2f}%\n")
            f.write(f"  Test Accuracy:  {test_accuracy*100:.2f}%\n")
            f.write(f"  Training Time:  {training_time:.2f}s\n\n")
            f.write(report)
        
        print(f"   ‚úì ƒê√£ l∆∞u classification report: {report_path}")
        
        # ====================================================================
        # 7. V·∫º V√Ä L∆ØU CONFUSION MATRIX
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 7: V·∫º V√Ä L∆ØU CONFUSION MATRIX")
        print("-" * 100)
        
        cm = confusion_matrix(y_test_encoded, y_test_pred)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=label_encoder.classes_,
                    yticklabels=label_encoder.classes_)
        plt.xlabel('Predicted Labels')
        plt.ylabel('True Labels')
        plt.title(f'Confusion Matrix\nkernel={kernel}, C={C}, gamma={gamma}')
        plt.tight_layout()
        
        cm_path = os.path.join(result_dir, 'confusion_matrix.png')
        plt.savefig(cm_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   ‚úì ƒê√£ l∆∞u confusion matrix: {cm_path}")
        
        # L∆∞u confusion matrix data
        cm_data_path = os.path.join(result_dir, 'confusion_matrix.pkl')
        with open(cm_data_path, 'wb') as f:
            pickle.dump({
                'confusion_matrix': cm,
                'class_names': label_encoder.classes_
            }, f)
        
        print(f"   ‚úì ƒê√£ l∆∞u confusion matrix data: {cm_data_path}")
        
        # ====================================================================
        # 8. L∆ØU ·∫¢NH PH√ÇN LO·∫†I SAI
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 8: L∆ØU ·∫¢NH PH√ÇN LO·∫†I SAI")
        print("-" * 100)
        
        # T√¨m c√°c ·∫£nh d·ª± ƒëo√°n sai
        wrong_indices = np.where(y_test_pred != y_test_encoded)[0]
        
        print(f"\n   üìä T·ªïng s·ªë ·∫£nh test: {len(y_test_encoded)}")
        print(f"   üìä S·ªë ·∫£nh d·ª± ƒëo√°n SAI: {len(wrong_indices)}")
        print(f"   üìä S·ªë ·∫£nh d·ª± ƒëo√°n ƒê√öNG: {len(y_test_encoded) - len(wrong_indices)}")
        print(f"   üìä T·ª∑ l·ªá sai: {len(wrong_indices)/len(y_test_encoded)*100:.2f}%")
        
        if len(wrong_indices) > 0:
            # T·∫°o th∆∞ m·ª•c misclassified_images
            misclassified_dir = os.path.join(result_dir, 'misclassified_images')
            os.makedirs(misclassified_dir, exist_ok=True)
            
            # ƒê·ªçc ·∫£nh g·ªëc t·ª´ test set
            import cv2
            test_dir = 'vn-signs/test'
            
            # T·∫°o mapping t·ª´ index ƒë·∫øn file path
            test_image_paths = []
            test_labels = []
            
            for class_name in sorted(os.listdir(test_dir)):
                class_path = os.path.join(test_dir, class_name)
                if not os.path.isdir(class_path):
                    continue
                
                for img_name in sorted(os.listdir(class_path)):
                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                        test_image_paths.append(os.path.join(class_path, img_name))
                        test_labels.append(class_name)
            
            # L∆∞u t·ª´ng ·∫£nh sai
            for idx in wrong_indices:
                true_label = label_encoder.classes_[y_test_encoded[idx]]
                pred_label = label_encoder.classes_[y_test_pred[idx]]
                
                # ƒê·ªçc ·∫£nh g·ªëc
                img_path = test_image_paths[idx]
                img = cv2.imread(img_path)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                # V·∫Ω ·∫£nh v·ªõi nh√£n
                fig, ax = plt.subplots(1, 1, figsize=(6, 6))
                ax.imshow(img)
                ax.axis('off')
                ax.set_title(f'True: {true_label}\nPredicted: {pred_label}', 
                           fontsize=12, color='red', weight='bold')
                
                # T√™n file
                img_filename = f"img{idx:03d}_true-{true_label}_pred-{pred_label}.png"
                save_path = os.path.join(misclassified_dir, img_filename)
                
                plt.tight_layout()
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                plt.close()
            
            print(f"   ‚úì ƒê√£ l∆∞u {len(wrong_indices)} ·∫£nh v√†o: {misclassified_dir}")
        else:
            print(f"   üéâ Kh√¥ng c√≥ ·∫£nh n√†o b·ªã d·ª± ƒëo√°n sai!")
        
        # ====================================================================
        # 9. L∆ØU TH√îNG TIN T·ªîNG H·ª¢P
        # ====================================================================
        print("\n" + "-" * 100)
        print("B∆Ø·ªöC 9: L∆ØU TH√îNG TIN T·ªîNG H·ª¢P")
        print("-" * 100)
        
        summary_path = os.path.join(result_dir, 'summary.txt')
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("T·ªîNG H·ª¢P K·∫æT QU·∫¢\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("SVM Parameters:\n")
            f.write(f"  kernel: {kernel}\n")
            f.write(f"  C:      {C}\n")
            f.write(f"  gamma:  {gamma}\n\n")
            
            f.write("CCV Parameters:\n")
            f.write(f"  target_size:  {target_size}\n")
            f.write(f"  n_bins:       {n_bins}\n")
            f.write(f"  threshold:    {threshold}\n")
            f.write(f"  color_space:  {color_space}\n\n")
            
            f.write("Dataset:\n")
            f.write(f"  Train samples: {len(X_train)}\n")
            f.write(f"  Test samples:  {len(X_test)}\n")
            f.write(f"  Features:      {X_train.shape[1]}\n")
            f.write(f"  Classes:       {len(label_encoder.classes_)}\n\n")
            
            f.write("Results:\n")
            f.write(f"  Train Accuracy: {train_accuracy*100:.2f}%\n")
            f.write(f"  Test Accuracy:  {test_accuracy*100:.2f}%\n")
            f.write(f"  Training Time:  {training_time:.2f}s\n\n")
            
            f.write("Misclassified:\n")
            f.write(f"  Total test:     {len(y_test_encoded)}\n")
            f.write(f"  Correct:        {len(y_test_encoded) - len(wrong_indices)}\n")
            f.write(f"  Wrong:          {len(wrong_indices)}\n")
            f.write(f"  Error rate:     {len(wrong_indices)/len(y_test_encoded)*100:.2f}%\n")
        
        print(f"   ‚úì ƒê√£ l∆∞u summary: {summary_path}")
        
        print("\n" + "=" * 100)
        print(f"‚úÖ HO√ÄN TH√ÄNH C·∫§U H√åNH [{config_idx}/{total_configs}]")
        print("=" * 100)
        
        return {
            'folder': folder_name,
            'train_accuracy': train_accuracy,
            'test_accuracy': test_accuracy,
            'training_time': training_time,
            'num_misclassified': len(wrong_indices)
        }
        
    except Exception as e:
        print(f"\n‚ùå L·ªñI: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    """
    H√†m main
    """
    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file k·∫øt qu·∫£
    result_file = 'grid_search_results/ccv_grid_search_20251124_015948.pkl'
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(result_file):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {result_file}")
        print("\nüí° Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n ƒë√∫ng ƒë·∫øn file .pkl")
        
        # T√¨m c√°c file .pkl trong th∆∞ m·ª•c grid_search_results
        results_dir = 'grid_search_results'
        if os.path.exists(results_dir):
            pkl_files = [f for f in os.listdir(results_dir) if f.endswith('.pkl')]
            if pkl_files:
                print(f"\nüìÅ C√°c file .pkl c√≥ s·∫µn trong {results_dir}:")
                for i, f in enumerate(pkl_files, 1):
                    print(f"   {i}. {f}")
        return
    
    # ========================================================================
    # B∆Ø·ªöC 1: PH√ÇN T√çCH K·∫æT QU·∫¢ GRID SEARCH
    # ========================================================================
    svm_best_results = analyze_grid_search_results(result_file)
    
    if svm_best_results is None:
        print("\n‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch k·∫øt qu·∫£!")
        return
    
    # ========================================================================
    # B∆Ø·ªöC 2: T·∫†O TH·ª¶ M·ª§C CCV_RESULTS
    # ========================================================================
    print("\n" + "=" * 100)
    print("T·∫†O TH·ª¶ M·ª§C CCV_RESULTS")
    print("=" * 100)
    
    results_base_dir = 'ccv_results'
    os.makedirs(results_base_dir, exist_ok=True)
    print(f"\n‚úì ƒê√£ t·∫°o th∆∞ m·ª•c: {results_base_dir}")
    
    # ========================================================================
    # B∆Ø·ªöC 3: HU·∫§N LUY·ªÜN V√Ä ƒê√ÅNH GI√Å T·ª™NG C·∫§U H√åNH
    # ========================================================================
    print("\n" + "=" * 100)
    print("HU·∫§N LUY·ªÜN V√Ä ƒê√ÅNH GI√Å T·ª™NG C·∫§U H√åNH SVM")
    print("=" * 100)
    
    total_configs = len(svm_best_results)
    print(f"\nüìä T·ªïng s·ªë c·∫•u h√¨nh c·∫ßn hu·∫•n luy·ªán: {total_configs}")
    
    all_results = []
    
    for i, config in enumerate(svm_best_results, 1):
        result = train_and_evaluate_svm_config(
            config, 
            config_idx=i, 
            total_configs=total_configs,
            results_base_dir=results_base_dir
        )
        
        if result is not None:
            all_results.append(result)
    
    # ========================================================================
    # B∆Ø·ªöC 4: T·ªîNG H·ª¢P K·∫æT QU·∫¢
    # ========================================================================
    print("\n" + "=" * 100)
    print("T·ªîNG H·ª¢P K·∫æT QU·∫¢ T·∫§T C·∫¢ C·∫§U H√åNH")
    print("=" * 100)
    
    if len(all_results) > 0:
        # S·∫Øp x·∫øp theo test accuracy
        all_results_sorted = sorted(all_results, key=lambda x: x['test_accuracy'], reverse=True)
        
        print(f"\nüèÜ B·∫¢NG X·∫æP H·∫†NG THEO TEST ACCURACY:")
        print("-" * 100)
        print(f"{'#':<4} {'Folder':<50} {'Train Acc':<12} {'Test Acc':<12} {'Time':<10} {'Errors':<8}")
        print("-" * 100)
        
        for i, result in enumerate(all_results_sorted, 1):
            print(f"{i:<4} {result['folder']:<50} "
                  f"{result['train_accuracy']*100:>10.2f}% "
                  f"{result['test_accuracy']*100:>10.2f}% "
                  f"{result['training_time']:>8.2f}s "
                  f"{result['num_misclassified']:>6}")
        
        # L∆∞u t·ªïng h·ª£p
        summary_all_path = os.path.join(results_base_dir, 'summary_all_configs.txt')
        with open(summary_all_path, 'w', encoding='utf-8') as f:
            f.write("=" * 100 + "\n")
            f.write("T·ªîNG H·ª¢P K·∫æT QU·∫¢ T·∫§T C·∫¢ C·∫§U H√åNH SVM\n")
            f.write("=" * 100 + "\n\n")
            f.write(f"Ng√†y: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"T·ªïng s·ªë c·∫•u h√¨nh: {len(all_results)}\n\n")
            
            f.write("B·∫¢NG X·∫æP H·∫†NG THEO TEST ACCURACY:\n")
            f.write("-" * 100 + "\n")
            f.write(f"{'#':<4} {'Folder':<50} {'Train Acc':<12} {'Test Acc':<12} {'Time':<10} {'Errors':<8}\n")
            f.write("-" * 100 + "\n")
            
            for i, result in enumerate(all_results_sorted, 1):
                f.write(f"{i:<4} {result['folder']:<50} "
                       f"{result['train_accuracy']*100:>10.2f}% "
                       f"{result['test_accuracy']*100:>10.2f}% "
                       f"{result['training_time']:>8.2f}s "
                       f"{result['num_misclassified']:>6}\n")
            
            f.write("\n" + "=" * 100 + "\n")
            f.write(f"üèÜ BEST CONFIGURATION:\n")
            f.write("-" * 100 + "\n")
            best = all_results_sorted[0]
            f.write(f"Folder:         {best['folder']}\n")
            f.write(f"Train Accuracy: {best['train_accuracy']*100:.2f}%\n")
            f.write(f"Test Accuracy:  {best['test_accuracy']*100:.2f}%\n")
            f.write(f"Training Time:  {best['training_time']:.2f}s\n")
            f.write(f"Misclassified:  {best['num_misclassified']}\n")
        
        print(f"\nüíæ ƒê√£ l∆∞u t·ªïng h·ª£p: {summary_all_path}")
        
        print("\n" + "=" * 100)
        print("‚úÖ HO√ÄN TH√ÄNH T·∫§T C·∫¢!")
        print("=" * 100)
        print(f"\nüìÅ T·∫•t c·∫£ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u trong: {results_base_dir}/")
        print(f"   - M·ªói c·∫•u h√¨nh SVM c√≥ 1 th∆∞ m·ª•c ri√™ng")
        print(f"   - M·ªói th∆∞ m·ª•c ch·ª©a:")
        print(f"     + Model (svm_model.pkl)")
        print(f"     + Label encoder (label_encoder.pkl)")
        print(f"     + Scaler (scaler.pkl)")
        print(f"     + Classification report (classification_report.txt)")
        print(f"     + Confusion matrix (confusion_matrix.png, .pkl)")
        print(f"     + Misclassified images (misclassified_images/)")
        print(f"     + Summary (summary.txt)")
    else:
        print("\n‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o!")


if __name__ == "__main__":
    main()

