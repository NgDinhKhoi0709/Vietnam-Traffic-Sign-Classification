# -*- coding: utf-8 -*-
"""
Grid Search cho HOG Features
T√¨m tham s·ªë t·ªët nh·∫•t cho HOG b·∫±ng c√°ch ƒë√°nh gi√° tr√™n t·∫≠p validation (20% t·ª´ train)
"""

import sys
import io
import numpy as np
import time
import pickle
import os
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
from itertools import product

# C·∫•u h√¨nh encoding UTF-8 cho Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from hog_feature import extract_hog_from_dataset


def grid_search_hog():
    """
    Grid search ƒë·ªÉ t√¨m tham s·ªë t·ªët nh·∫•t cho HOG
    """
    print("=" * 80)
    print("GRID SEARCH - HOG FEATURES")
    print("=" * 80)
    
    # ƒê·ªãnh nghƒ©a grid tham s·ªë
    param_grid = {
        'target_size': [(64, 64), (128, 128), (256, 256)],
        'orientations': [6, 9, 12],
        'pixels_per_cell': [(4, 4), (8, 8), (16, 16)],
        'cells_per_block': [(2, 2), (3, 3)],
    }
    
    # SVM parameters
    svm_params = {
        'kernel': 'rbf',
        'C': 10.0,
        'gamma': 'scale'
    }
    
    print("\nüìã Grid tham s·ªë:")
    for param, values in param_grid.items():
        print(f"   - {param}: {values}")
    
    print(f"\nüîß SVM parameters: {svm_params}")
    print(f"\nüìä T·ªïng s·ªë combinations: {np.prod([len(v) for v in param_grid.values()])}")
    
    # T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    results_dir = 'grid_search_results'
    os.makedirs(results_dir, exist_ok=True)
    
    # L∆∞u k·∫øt qu·∫£
    results = []
    best_accuracy = 0
    best_params = None
    
    # ƒê·∫øm combination
    total_combinations = np.prod([len(v) for v in param_grid.values()])
    current_combination = 0
    
    print("\n" + "=" * 80)
    print("B·∫ÆT ƒê·∫¶U GRID SEARCH")
    print("=" * 80)
    
    # Grid search
    for target_size, orientations, pixels_per_cell, cells_per_block in product(
        param_grid['target_size'],
        param_grid['orientations'],
        param_grid['pixels_per_cell'],
        param_grid['cells_per_block']
    ):
        current_combination += 1
        
        print(f"\n[{current_combination}/{total_combinations}] ƒêang th·ª≠:")
        print(f"   target_size={target_size}, orientations={orientations}")
        print(f"   pixels_per_cell={pixels_per_cell}, cells_per_block={cells_per_block}")
        
        try:
            start_time = time.time()
            
            # 1. Tr√≠ch xu·∫•t features t·ª´ train set
            print("   ‚Üí Tr√≠ch xu·∫•t features t·ª´ train set...")
            X_train_full, y_train_full, class_names = extract_hog_from_dataset(
                'vn-signs/train',
                target_size=target_size,
                orientations=orientations,
                pixels_per_cell=pixels_per_cell,
                cells_per_block=cells_per_block,
                use_cache=False  # Kh√¥ng d√πng cache v√¨ m·ªói l·∫ßn kh√°c tham s·ªë
            )
            
            if len(X_train_full) == 0:
                print("   ‚ùå Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c features, skip...")
                continue
            
            # Convert to numpy array
            X_train_full = np.array(X_train_full)
            
            # Encode labels
            label_encoder = LabelEncoder()
            y_train_full = label_encoder.fit_transform(y_train_full)
            
            # 2. Chia train/validation (80/20)
            X_train, X_val, y_train, y_val = train_test_split(
                X_train_full, y_train_full,
                test_size=0.2,
                random_state=42,
                stratify=y_train_full
            )
            
            print(f"   ‚Üí Train: {X_train.shape[0]} samples, Validation: {X_val.shape[0]} samples")
            
            # 3. Chu·∫©n h√≥a
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_val_scaled = scaler.transform(X_val)
            
            # 4. Train SVM
            print("   ‚Üí Training SVM...")
            svm = SVC(**svm_params, random_state=42)
            svm.fit(X_train_scaled, y_train)
            
            # 5. ƒê√°nh gi√° tr√™n validation
            y_val_pred = svm.predict(X_val_scaled)
            val_accuracy = accuracy_score(y_val, y_val_pred)
            
            # ƒê√°nh gi√° tr√™n train
            y_train_pred = svm.predict(X_train_scaled)
            train_accuracy = accuracy_score(y_train, y_train_pred)
            
            elapsed_time = time.time() - start_time
            
            print(f"   ‚úì Train Accuracy: {train_accuracy*100:.2f}%")
            print(f"   ‚úì Val Accuracy:   {val_accuracy*100:.2f}%")
            print(f"   ‚úì Time: {elapsed_time:.2f}s")
            
            # L∆∞u k·∫øt qu·∫£
            result = {
                'target_size': target_size,
                'orientations': orientations,
                'pixels_per_cell': pixels_per_cell,
                'cells_per_block': cells_per_block,
                'train_accuracy': train_accuracy,
                'val_accuracy': val_accuracy,
                'time': elapsed_time,
                'feature_dim': X_train.shape[1]
            }
            results.append(result)
            
            # C·∫≠p nh·∫≠t best
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                best_params = result.copy()
                print(f"   üèÜ NEW BEST! Val Accuracy: {best_accuracy*100:.2f}%")
            
        except Exception as e:
            print(f"   ‚ùå L·ªói: {e}")
            continue
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    print("\n" + "=" * 80)
    print("K·∫æT QU·∫¢ GRID SEARCH")
    print("=" * 80)
    
    if len(results) > 0:
        # S·∫Øp x·∫øp theo validation accuracy
        results_sorted = sorted(results, key=lambda x: x['val_accuracy'], reverse=True)
        
        print(f"\nüèÜ TOP 5 BEST CONFIGURATIONS:")
        print("-" * 80)
        for i, result in enumerate(results_sorted[:5], 1):
            print(f"\n{i}. Val Accuracy: {result['val_accuracy']*100:.2f}% | "
                  f"Train Accuracy: {result['train_accuracy']*100:.2f}%")
            print(f"   target_size={result['target_size']}, orientations={result['orientations']}")
            print(f"   pixels_per_cell={result['pixels_per_cell']}, cells_per_block={result['cells_per_block']}")
            print(f"   Feature dim: {result['feature_dim']}, Time: {result['time']:.2f}s")
        
        # L∆∞u k·∫øt qu·∫£ v√†o file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = os.path.join(results_dir, f'hog_grid_search_{timestamp}.pkl')
        
        with open(result_file, 'wb') as f:
            pickle.dump({
                'results': results,
                'best_params': best_params,
                'param_grid': param_grid,
                'svm_params': svm_params
            }, f)
        
        print(f"\nüíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {result_file}")
        
        # L∆∞u k·∫øt qu·∫£ d·∫°ng text
        txt_file = os.path.join(results_dir, f'hog_grid_search_{timestamp}.txt')
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write("GRID SEARCH RESULTS - HOG FEATURES\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total combinations tested: {len(results)}\n\n")
            
            f.write("BEST CONFIGURATION:\n")
            f.write("-" * 80 + "\n")
            f.write(f"Validation Accuracy: {best_params['val_accuracy']*100:.2f}%\n")
            f.write(f"Train Accuracy: {best_params['train_accuracy']*100:.2f}%\n")
            f.write(f"target_size: {best_params['target_size']}\n")
            f.write(f"orientations: {best_params['orientations']}\n")
            f.write(f"pixels_per_cell: {best_params['pixels_per_cell']}\n")
            f.write(f"cells_per_block: {best_params['cells_per_block']}\n")
            f.write(f"Feature dimension: {best_params['feature_dim']}\n")
            f.write(f"Time: {best_params['time']:.2f}s\n\n")
            
            f.write("\nALL RESULTS (sorted by validation accuracy):\n")
            f.write("-" * 80 + "\n")
            for i, result in enumerate(results_sorted, 1):
                f.write(f"\n{i}. Val Acc: {result['val_accuracy']*100:.2f}% | "
                       f"Train Acc: {result['train_accuracy']*100:.2f}%\n")
                f.write(f"   {result}\n")
        
        print(f"üíæ ƒê√£ l∆∞u b√°o c√°o text: {txt_file}")
        
        print("\n" + "=" * 80)
        print("‚úÖ HO√ÄN TH√ÄNH GRID SEARCH!")
        print("=" * 80)
    else:
        print("\n‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o!")


if __name__ == "__main__":
    grid_search_hog()

